# ğŸ‡ªğŸ‡¸ README.md en EspaÃ±ol

# ğŸ¤– Asistente Virtual "Sammy" para el Hotel ParaÃ­so CaribeÃ±o ğŸŒ´ (Notebook de Colab)

**Creado por: Grupo #3** ğŸ§‘â€ğŸ’»
**Curso: Talento Tech de MinTIC en alianza con la CUN** ğŸ“ğŸ‡¨ğŸ‡´

## 1. IntroducciÃ³n ğŸŒŸ

Este proyecto consiste en el desarrollo de "Sammy", un asistente virtual inteligente diseÃ±ado para el Hotel ParaÃ­so CaribeÃ±o, ubicado en la hermosa Santa Marta ğŸ–ï¸. Sammy tiene como objetivo principal mejorar la experiencia del cliente al proporcionar informaciÃ³n, gestionar consultas y ayudar con tareas como la verificaciÃ³n de usuarios, el registro y la creaciÃ³n de solicitudes de reserva ğŸ’¬.

El asistente ha sido desarrollado en un entorno de Google Colab, utilizando Python como lenguaje de programaciÃ³n principal y aprovechando las capacidades avanzadas del modelo de lenguaje grande (LLM) Gemini de Google ğŸ§  para la comprensiÃ³n del lenguaje natural y la generaciÃ³n de respuestas.

## 2. Objetivos del Proyecto ğŸ¯

* Crear un asistente conversacional capaz de entender y responder a las solicitudes de los usuarios de manera natural âœ”ï¸.
* Integrar el asistente con una base de datos (MongoDB Atlas ğŸ’¾) para gestionar informaciÃ³n de usuarios, paquetes, servicios y reservas.
* Implementar funcionalidades clave como:
    * Bienvenida y recolecciÃ³n de datos del usuario ğŸ‘‹.
    * VerificaciÃ³n de usuarios existentes y registro de nuevos usuarios ğŸ“.
    * Consulta de informaciÃ³n sobre paquetes de alojamiento, habitaciones y servicios/tours adicionales ğŸ¨ğŸ—ºï¸.
    * CreaciÃ³n de solicitudes de reserva, incluyendo la selecciÃ³n de paquetes y servicios ğŸ“….
    * Consulta del estado de reservas existentes ğŸ”.
    * ActualizaciÃ³n del estado de las reservas ğŸ”„.
* Proporcionar una interfaz de usuario interactiva dentro del notebook de Google Colab utilizando `ipywidgets` para facilitar la demostraciÃ³n y la interacciÃ³n ğŸ’».
* Demostrar el uso de la tÃ©cnica de "function calling" (uso de herramientas ğŸ› ï¸) con el LLM Gemini para realizar acciones especÃ­ficas y obtener datos de fuentes externas (la base de datos).

## 3. TecnologÃ­as Utilizadas âš™ï¸

* **Lenguaje de ProgramaciÃ³n:** Python ğŸ
* **Entorno de Desarrollo:** Google Colaboratory (Colab) â˜ï¸
* **Modelo de Lenguaje (IA):** API de Gemini (especÃ­ficamente, el modelo `gemini-1.5-flash-latest` o similar) a travÃ©s de la librerÃ­a `google-generativeai` ğŸ§ .
* **Base de Datos:** MongoDB Atlas (NoSQL, servicio en la nube), interactuando mediante la librerÃ­a `pymongo` ğŸ“Š.
* **Interfaz de Usuario en Colab:** `ipywidgets` para crear una experiencia de chat interactiva dentro del notebook ğŸ—£ï¸.
* **Manejo de Credenciales:** `google.colab.userdata` para acceder a API keys de forma segura ğŸ”‘.
* **Otras LibrerÃ­as Python:**
    * `os`
    * `datetime`
    * `uuid`
    * `html`

## 4. Estructura del Notebook de Colab ğŸ—ï¸

El proyecto en Google Colab estÃ¡ organizado en varias celdas, cada una con una responsabilidad especÃ­fica:

1.  **Celda 1: InstalaciÃ³n de LibrerÃ­as** ğŸ“¥:
    * Instala las dependencias necesarias (`google-generativeai`, `pymongo`, `ipywidgets`).
2.  **Celda 2: Importaciones Esenciales y ConfiguraciÃ³n Inicial** âš™ï¸:
    * Importa mÃ³dulos requeridos y define variables globales (URIs de conexiÃ³n, nombres de colecciones, API keys). Inicializa objetos de base de datos y el modelo de IA. Define `DEBUG_MODE`.
3.  **Celda 3: FunciÃ³n Auxiliar de SerializaciÃ³n** ğŸ”„:
    * Contiene `_serializar_documento_para_llm` para convertir datos de MongoDB (especialmente `ObjectId` y `datetime`) a un formato procesable por el LLM.
4.  **Celda 4: DefiniciÃ³n de Funciones Herramienta para Sammy** ğŸ› ï¸:
    * Define las funciones Python que Sammy (el LLM) puede "llamar" para interactuar con la base de datos o realizar cÃ¡lculos (ej. `Bienvenida_cliente`, `verificar_o_registrar_usuario`, `crear_reserva`). Agrupadas en `herramientas_disponibles_colab`.
5.  **Celda 5: FunciÃ³n de InicializaciÃ³n Principal (`inicializar_app_colab`)** â–¶ï¸:
    * Establece la conexiÃ³n con MongoDB Atlas.
    * Configura el cliente de Gemini con la API Key.
    * Crea la instancia del `GenerativeModel` de Gemini, pasÃ¡ndole las herramientas y la `system_instruction`.
    * Inicia la sesiÃ³n de chat (`chat_session_sammy`).
6.  **Celda 6: FunciÃ³n para Procesar Mensajes (`procesar_mensaje_colab`)** ğŸ’¬:
    * Maneja cada turno de la conversaciÃ³n. EnvÃ­a mensajes al `chat_session_sammy`, gestiona el bucle de "function calling" y extrae la respuesta final del LLM.
7.  **Celda 7: Interfaz GrÃ¡fica con `ipywidgets` y LÃ³gica de Chat** ğŸ–¥ï¸:
    * Define estilos HTML y crea widgets para la interfaz de chat. Implementa la lÃ³gica de la UI para mostrar la conversaciÃ³n y manejar interacciones. Llama a `inicializar_app_colab()` e inicia la interacciÃ³n.

## 5. Funcionamiento del Asistente (InteracciÃ³n con Gemini) ğŸ’¡

El nÃºcleo de la inteligencia de Sammy reside en el modelo Gemini y su capacidad de "function calling":

1.  **Prompt de Sistema (`system_instruction`)** ğŸ“œ: Define la personalidad de Sammy, su rol, objetivos y cÃ³mo/cuÃ¡ndo usar las funciones herramienta.
2.  **Mensaje del Usuario** ğŸ—£ï¸: El mensaje se pasa al modelo Gemini.
3.  **DecisiÃ³n del LLM** ğŸ¤”: El LLM decide si responder directamente o "llamar" a una funciÃ³n herramienta.
4.  **EjecuciÃ³n de la Herramienta (Python)** âš™ï¸: Si se llama a una herramienta, el cÃ³digo Python correspondiente se ejecuta (ej. consulta a MongoDB).
5.  **Resultado de la Herramienta al LLM** ğŸ“¤: El resultado de la funciÃ³n Python se envÃ­a de vuelta al LLM.
6.  **Respuesta Final del LLM** âœ…: El LLM formula una respuesta en lenguaje natural para el usuario, utilizando la informaciÃ³n de la herramienta si es necesario, pero sin mostrar el JSON crudo.

Este ciclo se repite para cada turno de la conversaciÃ³n ğŸ”.

## 6. CÃ³mo Usar el Notebook de Colab ğŸš€

1.  **Configurar Secrets** ğŸ”‘: Antes de ejecutar, configura las siguientes variables en los "Secrets" de Google Colab (icono de llave ğŸ—ï¸):
    * `MONGODB_ATLAS_URI`: Tu cadena de conexiÃ³n a MongoDB Atlas.
    * `GEMINI_API_KEY`: Tu clave API para los modelos Gemini de Google AI Studio.
2.  **Ejecutar Celdas en Orden** ğŸ”¢: Es crucial ejecutar todas las celdas del notebook en orden (Celda 1 a Celda 7).
3.  **Interactuar con Sammy** ğŸ’¬: Una vez que la Celda 7 se ejecute y muestre "Â¡Todo listo!...", podrÃ¡s usar la interfaz de chat para hablar con Sammy.
4.  **Modo de DepuraciÃ³n (`DEBUG_MODE`)** ğŸ: En la Celda 2, puedes cambiar `DEBUG_MODE = True` para ver logs detallados. Para una presentaciÃ³n limpia, mantenlo en `False`.
5.  **Finalizar** ğŸ›‘: Escribe "salir" en el chat para terminar la conversaciÃ³n.

## 7. Posibles Mejoras Futuras âœ¨

* ImplementaciÃ³n de una lÃ³gica de disponibilidad de habitaciones mÃ¡s robusta ğŸ›Œ.
* CÃ¡lculo de precios finales mÃ¡s preciso (considerando temporadas, ofertas, etc.) ğŸ’°.
* GestiÃ³n de sesiones de chat mÃ¡s avanzada para un entorno multiusuario ğŸ‘¥.
* IntegraciÃ³n con un frontend web externo (React, Vue) y un backend Flask/FastAPI desplegado en la nube ğŸŒ.
* AÃ±adir mÃ¡s herramientas para Sammy (ej. modificar reservas, obtener informaciÃ³n turÃ­stica de Santa Marta) ğŸ› ï¸â•.

---

Este proyecto demuestra una aplicaciÃ³n prÃ¡ctica de los modelos de lenguaje grandes con capacidad de uso de herramientas para crear asistentes virtuales funcionales y Ãºtiles. ğŸ‰

---
---

# ğŸ‡¬ğŸ‡§ README.md in English

# ğŸ¤– "Sammy" Virtual Assistant for ParaÃ­so CaribeÃ±o Hotel ğŸŒ´ (Colab Notebook)

**Created by: Group #3** ğŸ§‘â€ğŸ’»
**Course: Talento Tech by MinTIC in partnership with CUN** ğŸ“ğŸ‡¨ğŸ‡´

## 1. Introduction ğŸŒŸ

This project involves the development of "Sammy," an intelligent virtual assistant designed for the ParaÃ­so CaribeÃ±o Hotel, located in the beautiful Santa Marta ğŸ–ï¸. Sammy's main goal is to enhance the customer experience by providing information, managing inquiries, and assisting with tasks such as user verification, registration, and creating booking requests ğŸ’¬.

The assistant has been developed in a Google Colab environment, using Python as the primary programming language and leveraging the advanced capabilities of Google's Gemini Large Language Model (LLM) ğŸ§  for natural language understanding and response generation.

## 2. Project Objectives ğŸ¯

* Create a conversational assistant capable of understanding and responding to user requests naturally âœ”ï¸.
* Integrate the assistant with a database (MongoDB Atlas ğŸ’¾) to manage user information, packages, services, and reservations.
* Implement key functionalities such as:
    * Welcome and user data collection ğŸ‘‹.
    * Verification of existing users and registration of new users ğŸ“.
    * Querying information about accommodation packages, rooms, and additional services/tours ğŸ¨ğŸ—ºï¸.
    * Creating booking requests, including package and service selection ğŸ“….
    * Querying the status of existing reservations ğŸ”.
    * Updating the status of reservations ğŸ”„.
* Provide an interactive user interface within the Google Colab notebook using `ipywidgets` for easy demonstration and interaction ğŸ’».
* Demonstrate the use of the "function calling" technique (tool usage ğŸ› ï¸) with the Gemini LLM to perform specific actions and retrieve data from external sources (the database).

## 3. Technologies Used âš™ï¸

* **Programming Language:** Python ğŸ
* **Development Environment:** Google Colaboratory (Colab) â˜ï¸
* **Language Model (AI):** Gemini API (specifically, the `gemini-1.5-flash-latest` model or similar) via the `google-generativeai` library ğŸ§ .
* **Database:** MongoDB Atlas (NoSQL, cloud service), interacting via the `pymongo` library ğŸ“Š.
* **UI in Colab:** `ipywidgets` to create an interactive chat experience within the notebook ğŸ—£ï¸.
* **Credentials Management:** `google.colab.userdata` to securely access API keys ğŸ”‘.
* **Other Python Libraries:**
    * `os`
    * `datetime`
    * `uuid`
    * `html`

## 4. Colab Notebook Structure ğŸ—ï¸

The project in Google Colab is organized into several cells, each with a specific responsibility:

1.  **Cell 1: Install Libraries** ğŸ“¥:
    * Installs necessary dependencies (`google-generativeai`, `pymongo`, `ipywidgets`).
2.  **Cell 2: Essential Imports and Initial Configuration** âš™ï¸:
    * Imports required Python modules and defines global variables (connection URIs, collection names, API keys). Initializes database objects and the AI model. Defines `DEBUG_MODE`.
3.  **Cell 3: Auxiliary Serialization Function** ğŸ”„:
    * Contains `_serializar_documento_para_llm` to convert MongoDB data (especially `ObjectId` and `datetime`) into a format processable by the LLM.
4.  **Cell 4: Definition of Tool Functions for Sammy** ğŸ› ï¸:
    * Defines the Python functions that Sammy (the LLM) can "call" to interact with the database or perform calculations (e.g., `Bienvenida_cliente`, `verificar_o_registrar_usuario`, `crear_reserva`). Grouped in `herramientas_disponibles_colab`.
5.  **Cell 5: Main Initialization Function (`inicializar_app_colab`)** â–¶ï¸:
    * Establishes the connection with MongoDB Atlas.
    * Configures the Gemini client with the API Key.
    * Creates the Gemini `GenerativeModel` instance, passing it the tools and the `system_instruction`.
    * Starts the chat session (`chat_session_sammy`).
6.  **Cell 6: Message Processing Function (`procesar_mensaje_colab`)** ğŸ’¬:
    * Handles each turn of the conversation. Sends messages to `chat_session_sammy`, manages the "function calling" loop, and extracts the LLM's final response.
7.  **Cell 7: GUI with `ipywidgets` and Chat Logic** ğŸ–¥ï¸:
    * Defines HTML styles and creates widgets for the chat interface. Implements UI logic to display the conversation and handle user interactions. Calls `inicializar_app_colab()` and starts the interaction.

## 5. Assistant's Functionality (Interaction with Gemini) ğŸ’¡

The core of Sammy's intelligence lies in the Gemini model and its "function calling" capability:

1.  **System Prompt (`system_instruction`)** ğŸ“œ: Defines Sammy's personality, role, objectives, and how/when to use the tool functions.
2.  **User Message** ğŸ—£ï¸: The user's message is passed to the Gemini model.
3.  **LLM Decision** ğŸ¤”: The LLM decides whether to respond directly or "call" a tool function.
4.  **Tool Execution (Python)** âš™ï¸: If a tool is called, the corresponding Python code is executed (e.g., a MongoDB query).
5.  **Tool Result to LLM** ğŸ“¤: The result of the Python function is sent back to the LLM.
6.  **LLM Final Response** âœ…: The LLM formulates a natural language response for the user, using information from the tool if necessary, but without displaying raw JSON.

This cycle repeats for each turn in the conversation ğŸ”.

## 6. How to Use the Colab Notebook ğŸš€

1.  **Configure Secrets** ğŸ”‘: Before running, configure the following variables in Google Colab's "Secrets" (key icon ğŸ—ï¸):
    * `MONGODB_ATLAS_URI`: Your MongoDB Atlas connection string.
    * `GEMINI_API_KEY`: Your API key for Google AI Studio's Gemini models.
2.  **Run Cells in Order** ğŸ”¢: It is crucial to run all notebook cells in order (Cell 1 to Cell 7).
3.  **Interact with Sammy** ğŸ’¬: Once Cell 7 executes and displays "Â¡Todo listo!..." (All set!), you can use the chat interface to talk to Sammy.
4.  **Debug Mode (`DEBUG_MODE`)** ğŸ: In Cell 2, you can change `DEBUG_MODE = True` to see detailed logs. For a clean presentation, keep it `False`.
5.  **End** ğŸ›‘: Type "salir" in the chat to end the conversation.

## 7. Possible Future Improvements âœ¨

* Implementation of more robust room availability logic ğŸ›Œ.
* More accurate final price calculation (considering seasons, offers, etc.) ğŸ’°.
* More advanced chat session management for a multi-user environment ğŸ‘¥.
* Integration with an external web frontend (React, Vue) and a cloud-deployed Flask/FastAPI backend ğŸŒ.
* Adding more tools for Sammy (e.g., modifying reservations, obtaining tourist information for Santa Marta) ğŸ› ï¸â•.

---

This project demonstrates a practical application of large language models with tool-use capabilities to create functional and useful virtual assistants. ğŸ‰
